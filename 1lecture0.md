# what is it deep learning?

deep learning is a subset of machine learning which in turn is a subset of artificial intelligence which involves more traditional methods to learn representations directly from data

machine learning involves teaching computers to recognize patterns in data in the same way as our brains do so as humans it's easy for us to distinguish between a cat and a dog but it's much more difficult to teach a machine to do this and we'll talk more about this...


# amazing successes of deep learning in the past

in 1997 gary kasparov the most successful champion in the history of chess lost to ibm's deep blue one of the first computer or artificial systems. it was the first defeat of a reigning world chess champion by a computer

in 2011 ibm's watson competed in game show jeopardy against his champions brad rotter and ken jennings and won the first prize a million dollars

in 2015 alphago a deep learning computer program created by google's deepmind division defeated lee sedol an 18 time world champion at go a game of google more times complex than chess

to put it simply deep learning is a machine learning technique that learns features and tasks directly from data by running inputs through a biologically inspired neural network architecture

these neural networks contain a number of "hidden layers" through which data is processed allowing for the machine to go deep in its learning making connections and weighing input for the best results


# why deep learning?

the problem with traditional machine learning algorithms is that no matter how complex they get they'll always be machine like they need a lot of domain expertise human intervention and are only capable of what they're designed for

for example if i show you the image of a face you will automatically recognize it's a face but how would a computer know what this is?
well if we follow traditional machine learning we'd have to manually and painstakingly define to a computer what it faces for example it has eyes earsand mouth 

but now how do you define an eye or a mouth to a computer?
well if you look at an eye the corners are at some angle they're definitely not 90 degrees, they're definitely not zero degrees there's some angle in between so we could work with that and train our classifier to recognize these kinds of lines in certain orientations...this is complicated

for ai practitioners and the rest of the world that's where deep learning holds a bit of promise

the key idea in deep learning is that you can learn these features just from raw data so i can feed a bunch of images or faces to my deep learning algorithm and it's going to develop some kind of hierarchical representation of detecting lines and edges and then using these lines and edges to detect eyes and a mouth and composing it together to ultimately detect the face


as it turns out the underlying algorithms for training these models have existed for quite a long time
so why has deep learning gaining popularity many decades later?

well for one, data has become much more pervasive we're living in the age of big data and these algorithms require massive amounts of data to effectively be implemented

second we have hardware and architecture that are capable of handling the vast amount of data and computational power that these algorithms require hardware

that simply wasn't available a few decades ago

third building and deploying these
algorithms models as i call is extremely streamlined with the increasing popularity of open source software like tensorflow and pytorch

"Streamline" can also refer to the process of making something more efficient or optimizing it. This can apply to various contexts, such as streamlining a production process or streamlining a computer program to make it run faster and use fewer resources.


1. Data is prevalent
#### The term "prevalent" is generally used to describe something that is widespread, commonly accepted, or practiced. It signifies that something is widespread or commonly found in a particular context.

2. Improved Hardware Architecture

3. New Software Architecture
